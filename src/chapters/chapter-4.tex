\chapter{Pengujian}

Bab ini membahas pengujian normalisasi teks pada metode normalisasi teks \parencite{saragih2017normalisasi}, metode normalisasi teks dengan jarak Jaro-Winkler, dan metode normalisasi teks dengan jarak Levenshtein. Pembahasan yang tertera meliputi perangkat dan lingkungan yang digunakan untuk pengujian, metode pengujian, skenario pengujian, serta hasil dan analisis pengujian.

\section{Perangkat dan Lingkungan Pengujian}

Pengujian ketiga metode dilakukan dengan menggunakan perangkat laptop dengan spesifikasi sebagai berikut:
\begin{enumerate}
    \item Spesifikasi Perangkat Keras:
    \begin{enumerate}
        \NumTabs{6}
        \setlength{\itemsep}{1pt}
        \item Perangkat \tab \tab : ASUS X450LD tahun 2014
        \item Prosessor \tab \tab : 1,6 GHz Intel Core i5 4200U
        \item Memori \tab \tab : 4 GB DDR3
        \item Penyimpanan \tab : HDD 500 GB
        \item Sistem Operasi \tab : Windows 10 64bit
    \end{enumerate}
    \item Alat Bantu Pengembangan: Visual Studio Code, Anaconda, Jupyter Notebook
    \item Bahasa Pemrograman: Python 3.6.5 64bit
    \item \textit{Library} Python yang Digunakan: \textit{csv} \parencite{pythoncsv}, \textit{textdistance} \parencite{orsiniumtext}
\end{enumerate}

\section{Metode Pengujian}

Pengujian dilakukan dengan melakukan perbandingan antara metode normalisasi teks \parencite{saragih2017normalisasi}, metode normalisasi dengan jarak Jaro-Winkler, dan metode normalisasi teks dengan jarak Levenshtein. Ketiga metode normalisasi diberikan masukan yang sama. Keluaran dari ketiga metode dinilai dengan menggunakan persentase akurasi yang disesuaikan dengan skenario yang berbeda. Penilaian persentase akurasi dilakukan dengan menggunakan persamaan:
\begin{equation*}
	\text{Persentase akurasi}=\frac{\text{x}}{y} \times 100\%
\end{equation*}
%\myequations{Penghitungan akurasi fungsi \textit{stringdist}}
\noindent
dengan $x$ adalah jumlah kata yang sesuai dengan perbaikan kata, dan $y$ adalah jumlah seluruh kata yang termasuk dalam data uji \parencite{saragih2017normalisasi}.

\subsection{Masukan}

Terdapat dua masukan yang termasuk dalam pengujian, yaitu data uji, serta kamus kata baku.

\subsubsection{Data Uji}

Data uji yang digunakan dalam pengujian diambil dari kumpulan kata tidak baku yang berada dalam kamus KBBI \parencite{sinaukbbi}. Tabel \ref{tbl:test_data} menunjukkan 5 contoh data yang digunakan dalam pengujian. Data uji terdiri dari kata tidak baku dan perbaikan dari kata tidak baku tersebut menjadi kata baku. Berikut merupakan deskripsi dari data uji yang digunakan:
\begin{enumerate}
    \item Jumlah kata: 2.398 kata
    \item Sumber data: berkas CSV dari perangkat lunak KBBI \textit{offline} \parencite{sinaukbbi} sejumlah 35.969 baris, terdiri dari 3 kolom yaitu kolom \textit{id}, kata, dan arti kata
    \item Praproses data: \begin{enumerate}
        \item Kamus KBBI dibersihkan dari kata tidak baku;
        \item kata-kata tidak baku dikumpulkan; dan
        \item mengolah arti kata menjadi perbaikan kata.
    \end{enumerate}
\end{enumerate}
\begin{table}[ht]
    \captionsetup{justification=justified,singlelinecheck=false}
    \caption{Lima (5) kata pertama dalam data uji beserta perbaikannya}
    \label{tbl:test_data}
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Kata tidak baku} & \textbf{Perbaikan kata} \\ \hline
        abadiat & abadiah \\
        abdul & abdu \\
        abimana & abaimana \\
        ablur & hablur \\
        adan & azan \\ \hline
    \end{tabular}
\end{table}

Sebagai catatan, semua kata dalam kata uji merupakan kata-kata yang tidak disingkat. Contohnya, salah satu kata dalam data uji adalah "\textit{apotik}" dengan kata perbaikan berupa "apotek", namun kata seperti "\textit{aptk}" tidak termasuk dalam data uji.

\subsubsection{Kamus Kata Baku}

Kamus kata baku yang digunakan berasal dari penggabungan antara kamus dalam perangkat lunak KBBI \textit{offline} \parencite{sinaukbbi} dan kamus dari korpus arsip Kompas tahun 2012 \parencite{lanin2013distribusi}. Kedua kamus tersebut dibersihkan dari kata-kata tidak baku, lalu seluruh kata dalam kamus diurutkan berdasarkan kamus korpus Kompas. Tabel \ref{tbl:dictionary_kbbi-kompas} menunjukkan 15 kata pertama yang ada dalam kamus kata baku. Berikut merupakan deskripsi dari kamus kata baku yang digunakan untuk pengujian ini:
\begin{enumerate}
    \item Jumlah kata: 29.194 kata
    \item Sumber data: \begin{enumerate}
        \item Berkas CSV dari perangkat lunak KBBI \textit{offline} \parencite{sinaukbbi} sejumlah 35.969 kata, terdiri dari 3 kolom yaitu kolom \textit{id}, kata, dan arti kata; dan
        \item korpus arsip Kompas tahun 2012 \parencite{lanin2013distribusi} sejumlah 10.000 kata, terdiri dari 3 kolom yaitu kolom kata, jumlah kata dalam korpus, dan persentase jumlah kata terhadap seluruh isi korpus.
    \end{enumerate}
    \item Praproses data: \begin{enumerate}
        \item Kamus KBBI dibersihkan dari kumpulan kata tidak baku;
        \item kamus korpus Kompas dibersihkan dari kata tidak baku dengan bantuan kamus KBBI; dan
        \item melakukan penggabungan antara kata dalam kamus korpus Kompas dengan kata dalam kamus KBBI.
    \end{enumerate}
\end{enumerate}
\begin{table}[H]
    \captionsetup{justification=justified,singlelinecheck=false}
    \caption{Lima belas (15) kata pertama dalam kamus kata baku}
    \label{tbl:dictionary_kbbi-kompas}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \multicolumn{3}{|c|}{\textbf{Kamus Kompas-KBBI}} \\ \hline
        yang & dengan & pada \\
        di & untuk & tidak \\
        dan & dari & juga \\
        ini & dalam & ke \\
        itu & akan & tersebut \\ \hline
    \end{tabular}
\end{table}

\subsection{Keluaran}

Keluaran dari ketiga metode normalisasi adalah sebuah vektor yang berisi kumpulan kata prediksi dalam kamus kata baku yang memiliki jarak paling kecil dari kata dalam data uji. Tabel \ref{tbl:output} menunjukkan contoh keluaran yang muncul jika ketiga metode normalisasi diberikan masukan tertentu.
\begin{table}[ht]
    \captionsetup{justification=justified,singlelinecheck=false}
    \caption{Contoh keluaran ketiga metode terhadap masukan kata}
    \label{tbl:output}
    \centering
    \begin{tabularx}{\textwidth}{|c|X|X|X|}
        \hline
        \textbf{Contoh kata} & \multicolumn{1}{c|}{\textbf{Contoh keluaran}} & \multicolumn{1}{c|}{\textbf{Contoh keluaran}} & \multicolumn{1}{c|}{\textbf{Contoh keluaran}} \\
        \textbf{masukan} & \multicolumn{1}{c|}{\textbf{metode \parencite{saragih2017normalisasi}}} & \multicolumn{1}{c|}{\textbf{metode Jaro-Winkler}} & \multicolumn{1}{c|}{\textbf{metode Levenshtein}} \\ \hline
        \textit{abadiat} & {[}'abadi', 'abadiah', 'ahadiat', 'baiat'] & {[}'abadi', 'abadiah'] & {[}'abadiah', 'ahadiat'] \\ \hline
        \textit{abdul} & {[}'abdu', 'abul'] & {[}'abdu'] & {[}'abdu', 'abul'] \\ \hline
        \textit{abimana} & {[}'abaimana'] & {[}'abian'] & {[}'abaimana'] \\ \hline
    \end{tabularx}
\end{table}

\section{Skenario Pengujian}

Penilaian akurasi keluaran ketiga metode normalisasi ditentukan oleh skenario pengujian yang dilakukan. Terdapat dua skenario yang akan dijalankan dalam pengujian ini.

\subsection{Skenario Pertama: Melihat Kata Pertama dalam Kumpulan Kata}

Skenario pertama adalah penilaian dilakukan dengan melihat kesesuaian antara perbaikan kata dengan kata pertama dalam kumpulan kata prediksi. Contoh skenario pertama dapat dilihat pada Gambar \ref{fig:skenario1_eg}. Penilaian hanya melihat kesesuaian antara perbaikan kata suatu kata tidak baku dengan kata pertama dalam kumpulan kata prediksi. Jika sesuai, maka kumpulan kata prediksi tersebut dianggap sesuai. Jika tidak sesuai, maka kumpulan kata prediksi dianggap tidak sesuai meskipun kemungkinan perbaikan kata ternyata berada pada urutan lain dalam kumpulan kata prediksi.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth, trim=2 2 2 2, clip]{resources/4/skenario1_eg.pdf}
	\caption{Contoh penilaian untuk pengujian skenario pertama}
	\label{fig:skenario1_eg}
\end{figure}

\subsection{Skenario Kedua: Melihat Seluruh Isi Kumpulan Kata}

Skenario kedua adalah penilaian dilakukan dengan melihat apakah terdapat perbaikan kata di dalam kumpulan kata prediksi. Contoh untuk skenario kedua dapat dilihat pada Gambar \ref{fig:skenario2_eg}. Seluruh kata dalam kumpulan kata prediksi diperiksa untuk menemukan salah satu kata yang sesuai dengan perbaikan kata. Jika ditemukan, maka kumpulan kata prediksi tersebut dianggap sesuai.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth, trim=2 2 2 2, clip]{resources/4/skenario2_eg.pdf}
	\caption{Contoh penilaian untuk pengujian skenario pertama}
	\label{fig:skenario2_eg}
\end{figure}

\section{Hasil Pengujian}

\subsection{Hasil Pengujian Skenario Pertama}

Hasil pengujian untuk skenario pengujian ditunjukkan pada Tabel \ref{tbl:result_1}. Hasil pengujian menunjukkan bahwa metode normalisasi yang diusulkan mengungguli kedua metode normalisasi yang lain dengan selisih akurasi dengan metode \parencite{saragih2017normalisasi} sebesar 6,35 persen. Metode normalisasi dengan Jaro-Winkler menempati peringkat terakhir dengan selisih akurasi dengan metode normalisasi \parencite{saragih2017normalisasi} sebesar 0,83 persen.
\begin{table}[ht]
    \captionsetup{justification=justified,singlelinecheck=false}
    \caption{Hasil akurasi untuk pengujian ketiga metode normalisasi dalam skenario pertama}
    \label{tbl:result_1}
    \centering
    \begin{tabularx}{\textwidth}{|X|c|c|c|}
        \hline
        \multicolumn{1}{|Y|}{\textbf{Metode}} & \textbf{Jumlah kata benar} & \textbf{Akurasi} \\ \hline
        Metode Normalisasi \parencite{saragih2017normalisasi} & 622 & 25,93\% \\ \hline
        Metode Normalisasi dengan Jaro-Winkler & 602 & 25,10\% \\ \hline
        Metode Normalisasi dengan Levenshtein & 774 & 32,28\% \\ \hline
    \end{tabularx}
\end{table}

Hasil metode normalisasi Jaro-Winkler yang berada di posisi terakhir disebabkan oleh teknik Jaro-Winkler dalam menentukan kemiripan antara kedua kata. Jaro-Winkler menganggap bahwa kedua kata dikatakan mirip jika terdapat karakter yang sesuai dengan jumlah yang banyak serta tidak ada transposisi dengan karakter yang sesuai tersebut. Maka, Jaro-Winkler akan menganggap kata dengan penambahan satu karakter memiliki kemiripan yang lebih tinggi dibandingkan kata dengan penggantian satu karakter saja, mengakibatkan kata yang mengalami penggantian karakter tergusur dari pencarian kata baku. Sebagai contoh, kata "\textit{asem}" memiliki kemiripan yang lebih tinggi dengan "rasem" dibandingkan dengan "asam", dengan nilai kemiripan masing-masing adalah 93,33 persen dan 86,67 persen.

Meskipun begitu, hasil akurasi pengujian untuk ketiga metode masih menunjukkan angka di bawah 50 persen. Hal tersebut disebabkan oleh perbaikan kata uji bukan merupakan kata yang berada dalam urutan pertama kumpulan kata prediksi. Hal tersebut berarti perbaikan kata uji bukan merupakan kata yang sering digunakan dalam korpus Kompas. Sebagai contoh, perbaikan kata "\textit{asem}" seharusnya adalah "asam", namun dalam metode normalisasi Levenshtein, kata "\textit{asem}" diidentifikasi sebagai "aset" yang mana "aset" adalah kata yang berada pada urutan pertama dalam kumpulan kata prediksi. Setelah melihat isi kumpulan kata prediksi, ternyata kata "asam" terdapat dalam kumpulan kata tersebut.

Untuk melihat adanya kata perbaikan yang masuk ke dalam kumpulan kata dengan jarak perubahan minimum, diperlukan skenario baru, yaitu dengan modifikasi algoritme penilaian pada ketiga metode normalisasi (skenario kedua). Gambar \ref{fig:skenario_side_to_side} menunjukkan perbedaan antara skenario pertama dengan skenario kedua. Jika skenario pertama hanya memeriksa urutan pertama dari kumpulan kata prediksi, skenario kedua memeriksa seluruh kumpulan kata prediksi hingga ditemukan kata yang sesuai dengan perbaikan kata.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth, trim=2 2 2 2, clip]{resources/4/skenario_side_to_side.pdf}
	\caption{Perbedaan antara (a) skenario pertama, dan (b) skenario kedua}
	\label{fig:skenario_side_to_side}
\end{figure}

\subsection{Hasil Pengujian Skenario Kedua}

Hasil pengujian untuk skenario kedua disajikan pada Tabel \ref{tbl:result_2}, dan hasil untuk kedua pengujian dapat dilihat pada Gambar \ref{fig:ss_pengujian} Hasil pengujian tersebut menunjukkan peningkatan yang signifikan untuk selisih antara metode normalisasi Levenshtein dengan kedua metode normalisasi yang lain. Hasil akurasi untuk metode normalisasi Levenshtein masih mengungguli metode normalisasi \parencite{saragih2017normalisasi} dengan selisih sebesar 18,89 persen. Metode normalisasi dengan Jaro-Winkler masih tetap berada di posisi terakhir dengan selisih akurasi 21,6 persen dari metode normalisasi \parencite{saragih2017normalisasi}.
\begin{table}[ht]
    \captionsetup{justification=justified,singlelinecheck=false}
    \caption{Hasil akurasi untuk pengujian ketiga metode normalisasi dalam skenario kedua}
    \label{tbl:result_2}
    \centering
    \begin{tabularx}{\textwidth}{|X|c|c|c|}
        \hline
        \multicolumn{1}{|Y|}{\textbf{Metode}} & \textbf{Jumlah kata benar} & \textbf{Akurasi} \\ \hline
        Metode Normalisasi \parencite{saragih2017normalisasi} & 1233 & 51,42\% \\ \hline
        Metode Normalisasi dengan Jaro-Winkler & 715 & 29,82\% \\ \hline
        Metode Normalisasi dengan Levenshtein & 1686 & 70,31\% \\ \hline
    \end{tabularx}
\end{table}
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth, trim=2 2 2 2, clip]{resources/4/ss_pengujian.png}
	\caption{Seluruh hasil pengujian ketiga metode dengan menggunakan Jupyter Notebook}
	\label{fig:ss_pengujian}
\end{figure}

Hasil akurasi metode normalisasi dengan Jaro-Winkler yang masih di bawah 50 persen masih disebabkan oleh satuan penilaian kemiripan yang digunakan oleh Jaro-Winkler. Satuan penilaian yang digunakan adalah bilangan desimal, yang mana bilangan tersebut lebih sensitif terhadap perubahan dibandingkan dengan bilangan bulat. Hal tersebut mengakibatkan kumpulan kata dengan kemiripan tertinggi sementara tergusur dengan mudah oleh kata baru dengan kemiripan yang lebih tinggi.

Meskipun hasil akurasi bertambah dibandingkan sebelumnya, persentase akurasi belum menyentuh angka 100 persen. Hal tersebut dapat disebabkan oleh jarak perubahan antara kata tidak baku dan perbaikan kata uji tidak termasuk dalam kumpulan kata dengan jarak perubahan minimum. Beberapa kata perbaikan dalam data uji memiliki jarak yag lebih besar dari jarak minimum yang ditemukan antara kata dalam data uji dengan beberapa kata dalam kamus kata baku. Sebagai contoh, kata "\textit{telepa}" merupakan kata tidak baku dari kata "telap" dan jarak perubahan antara kedua kata adalah 3 dengan jarak LCS dan 2 dengan jarak Levenshtein. Namun, ketiga metode normalisasi dapat menemukan kumpulan kata prediksi yang memiliki jarak perubahan yang lebih kecil dibandingkan jarak perubahan antara "\textit{telepa}" dan "telap" sehingga kata "telap" tidak dapat ditemukan.

Hasil pengujian tersebut menunjukkan bahwa masalah yang terjadi jika perbaikan kata uji telah diselesaikan, jika algoritme dalam metode normalisasi dapat melhat seluruh kata yang terkandung pada kumpulan kata prediksi. Namun, algoritme tersebut hanya dapat melihat kumpulan kata. Algoritme tidak dapat menentukan kata yang tepat digunakan, jika algoritme ingin diterapkan dalam sistem \textit{voice assistant}. Untuk penerapan dalam sistem \textit{voice assistant}, metode normalisasi juga harus dapat menentukan kata dalam kumpulan kata prediksi yang tepat digunakan.

\section{Kesimpulan Pengujian}

Pengujian yang telah dilakukan menghasilkan kesimpulan, bahwa metode normalisasi dengan jarak Levenshtein lebih cocok digunakan untuk digunakan sebagai normalisasi kata tidak baku yang tidak disingkat dibandingkan dengan metode normalisasi dengan jarak Jaro-Winkler. Hal tersebut ditunjukkan dengan unggulnya metode normalisasi dengan Levenshtein dalam semua skenario pengujian, sedangkan metode normalisasi dengan Jaro-Winkler tidak mampu mengungguli metode normalisasi \parencite{saragih2017normalisasi}.